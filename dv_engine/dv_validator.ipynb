{"cells":[{"cell_type":"code","source":["import re\n","from typing import List\n","\n","class SQLValidator:\n","    \"\"\"Minimal SQL injection protection for controlled environments\"\"\"\n","    \n","    # Core reserved keywords that cause actual problems\n","    CRITICAL_KEYWORDS = {\n","        'select', 'from', 'where', 'drop', 'delete', 'insert', \n","        'update', 'union', 'exec', 'execute'\n","    }\n","    \n","    # Single regex for all dangerous patterns\n","    DANGEROUS_PATTERN = re.compile(\n","        r\"--|/\\*|\\*/|;|'|\\\"|\\\\|0x[0-9a-f]+|\\$\\{\",\n","        re.IGNORECASE\n","    )\n","    \n","    @staticmethod\n","    def validate_identifier(identifier: str, allow_dots: bool = False) -> None:\n","        \"\"\"Fast, minimal validation for identifiers\"\"\"\n","        if not identifier or not isinstance(identifier, str):\n","            raise ValueError(f\"Invalid identifier: empty or not string\")\n","        \n","        # Strip backticks if present\n","        clean = identifier.strip('`')\n","        \n","        # Check dangerous patterns (fastest check first)\n","        if SQLValidator.DANGEROUS_PATTERN.search(clean):\n","            raise ValueError(f\"Identifier contains dangerous characters: {identifier}\")\n","        \n","        # Basic character check\n","        pattern = r'^[a-zA-Z0-9_\\.]+$' if allow_dots else r'^[a-zA-Z0-9_]+$'\n","        if not re.match(pattern, clean):\n","            raise ValueError(f\"Identifier contains invalid characters: {identifier}\")\n","        \n","        # Must start with letter or underscore\n","        if not clean[0].isalpha() and clean[0] != '_':\n","            raise ValueError(f\"Identifier must start with letter/underscore: {identifier}\")\n","        \n","        # Check critical reserved keywords only\n","        if clean.lower() in SQLValidator.CRITICAL_KEYWORDS:\n","            raise ValueError(f\"Identifier is a reserved keyword: {identifier}\")\n","    \n","    @staticmethod\n","    def validate_batch(identifiers: List[str], allow_dots: bool = False) -> None:\n","        \"\"\"Validate multiple identifiers efficiently\"\"\"\n","        errors = []\n","        for idx, identifier in enumerate(identifiers):\n","            try:\n","                SQLValidator.validate_identifier(identifier, allow_dots)\n","            except ValueError as e:\n","                errors.append(f\"[{idx}] {identifier}: {str(e)}\")\n","        \n","        if errors:\n","            raise ValueError(f\"Validation failed:\\n\" + \"\\n\".join(errors))\n","\n","class Validator:\n","    def _add_issue(self, severity: WarningSeverity, stage: str, entity: str, \n","                   message: str, details: Optional[Dict] = None):\n","        \"\"\"Add a validation issue to the collection\"\"\"\n","        self._validation_issues.append(\n","            ValidationIssue(severity, stage, entity, message, details)\n","        )\n","        if severity == WarningSeverity.ERROR:\n","            self._has_errors = True\n","    \n","    def _validate_identifier(self, identifier: str, allow_dots: bool = False) -> None:\n","        \"\"\"Fast validation wrapper\"\"\"\n","        try:\n","            self.validator.validate_identifier(identifier, allow_dots)\n","        except ValueError as e:\n","            self._add_issue(WarningSeverity.ERROR, \"validation\", \"identifier\", str(e))\n","            raise\n","    \n","    def _validate_batch(self, identifiers: List[str]) -> None:\n","        \"\"\"Batch validate for performance\"\"\"\n","        try:\n","            self.validator.validate_batch(identifiers, allow_dots=False)\n","        except ValueError as e:\n","            self._add_issue(WarningSeverity.ERROR, \"validation\", \"identifiers\", str(e))\n","            raise\n","\n","    def _validate_satellite_parent(self, sat: Satellite) -> None:\n","        all_parents = self._get_all_parents()\n","        \n","        if sat.parent_hub_or_link not in all_parents:\n","            self._add_issue(\n","                WarningSeverity.ERROR,\n","                \"satellite\",\n","                sat.name,\n","                f\"Parent '{sat.parent_hub_or_link}' not found\",\n","                {\"available\": sorted(all_parents)}\n","            )\n","\n","    def _check_vault_entity_duplicate(self, name: str, collection: list, entity_type: str) -> bool:\n","        if any(item.name == name for item in collection):\n","            self._add_issue(\n","                WarningSeverity.ERROR,\n","                entity_type,\n","                name,\n","                f\"Duplicate {entity_type} name '{name}' â€” already registered\"\n","            )\n","            return True\n","        return False\n","\n","    def _detect_duplicate_satellites(self) -> None:\n","        \"\"\"Detect satellites with duplicate descriptive columns on same source\"\"\"\n","        \n","        # Group satellites by source table\n","        by_source = {}\n","        for sat in self._sats:\n","            if sat.source_table not in by_source:\n","                by_source[sat.source_table] = []\n","            by_source[sat.source_table].append(sat)\n","        \n","        # Collect all duplicates: {source_table: {signature: [satellites]}}\n","        all_duplicates = {}\n","        \n","        for source_table, satellites in by_source.items():\n","            column_signatures = {}\n","            \n","            for sat in satellites:\n","                try:\n","                    resolved_cols = sat.resolved_columns\n","                except RuntimeError:\n","                    continue\n","\n","                signature = tuple(sorted(resolved_cols))\n","                \n","                if signature not in column_signatures:\n","                    column_signatures[signature] = []\n","                column_signatures[signature].append(sat)\n","            \n","            # Filter to only duplicates (2+ satellites with same signature)\n","            duplicates = {\n","                sig: sats for sig, sats in column_signatures.items() \n","                if len(sats) > 1\n","            }\n","            \n","            if duplicates:\n","                all_duplicates[source_table] = duplicates\n","        \n","        # Print all duplicates at once\n","        if all_duplicates:\n","            # print(\"DUPLICATE SATELLITE COLUMNS DETECTED\")\n","            \n","            for source_table, duplicates in all_duplicates.items():\n","                # print(f\"Source Table: {source_table}\")\n","                \n","                for signature, satellites in duplicates.items():\n","                    sat_names = [sat.name for sat in satellites]\n","                    \n","                    # print(f\"  Columns: {list(signature)}\")\n","                    # print(f\"  Satellites ({len(satellites)}):\")\n","                    # for sat in satellites:\n","                    #     print(f\"    - {sat.name}\")\n","                    \n","                    # Add issue for each duplicate group\n","                    self._add_issue(\n","                        WarningSeverity.WARNING,\n","                        \"satellite\",\n","                        \", \".join(sat_names),\n","                        f\"{len(satellites)} satellites share identical descriptive columns on '{source_table}'\",\n","                        {\n","                            \"source_table\": source_table,\n","                            \"columns\": list(signature),\n","                            \"satellites\": sat_names,\n","                            \"impact\": f\"All {len(satellites)} satellites will generate identical hash diffs in staging table\",\n","                            \"suggestion\": \"Consider using different columns or combining into one satellite\"\n","                        }\n","                    )\n","\n","    def _validate_all_columns(self) -> None:\n","        \"\"\"Validate all entity columns exist in their source tables.\"\"\"\n","\n","        for hub in self._hubs:\n","            self._validate_columns_exist(\n","                entity_name=hub.name,\n","                entity_type=\"hub\",\n","                columns=hub.business_key_columns,\n","                source_table=hub.source_table\n","            )\n","        \n","        for sat in self._sats:\n","            columns = sat.resolved_columns if sat._resolved_columns else sat.descriptive_columns\n","            self._validate_columns_exist(\n","                entity_name=sat.name,\n","                entity_type=\"satellite\",\n","                columns=columns,\n","                source_table=sat.source_table\n","            )\n","            # TODO: if it's a new stage, ofc it will fail\n","            # if self._registered_hubs or self._registered_links:\n","            #     columns.extend(sat._stage.columns)\n","            #     self._validate_columns_exist(\n","            #         entity_name=sat.name,\n","            #         entity_type=\"satellite\",\n","            #         columns=columns,\n","            #         source_table=f\"{sat._stage.schema}.{sat._stage.table}\"\n","            #     )\n","\n","    def _validate_columns_exist(\n","        self, \n","        entity_name: str, \n","        entity_type: str, \n","        columns: List[str], \n","        source_table: str\n","    ) -> None:\n","        \"\"\"Check if columns exist in source table.\"\"\"\n","        \n","        source_columns = self._get_source_columns(source_table)\n","        \n","        if not source_columns:\n","            return  # Error already logged\n","        \n","        source_lower = {c.lower() for c in source_columns}\n","        \n","        missing = [c for c in columns if c.lower() not in source_lower]\n","        \n","        if missing:\n","            self._add_issue(\n","                WarningSeverity.ERROR,\n","                entity_type,\n","                entity_name,\n","                f\"Column(s) not found in source: {missing}\",\n","                {\n","                    \"source_table\": source_table,\n","                    \"missing_columns\": missing,\n","                    \"available_columns\": sorted(source_columns)[:15]\n","                }\n","            )\n","    \n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"19eb0bd6-a888-4f51-9db8-aee38ec531aa"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}